# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/06_accel_sgd.ipynb.

# %% ../nbs/06_accel_sgd.ipynb 2
from __future__ import annotations
import math, random, torch, matplotlib.pyplot as plt, numpy as np
from pathlib import Path
from operator import itemgetter
from itertools import zip_longest
from functools import partial
import fastcore.all as fc

from torch import tensor, nn, optim
import torch.nn.functional as F
from datasets import load_dataset
from tqdm.auto import tqdm
import torchvision.transforms.functional as TF
from torch.optim import lr_scheduler

from .learner import *
from .datasets import *
from .conv import *
from .activations import *
from .core import *
from .initialisation import *

import re
from torcheval.metrics import MulticlassAccuracy

torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)
torch.manual_seed(1)

# %% auto 0
__all__ = ['set_seed', 'LRScheduler', 'SingleBatch']

# %% ../nbs/06_accel_sgd.ipynb 4
def set_seed(seed, deterministic=False):
    torch.use_deterministic_algorithms(deterministic)
    torch.manual_seed(seed)
    random.seed(seed)
    np.random.seed(seed)

# %% ../nbs/06_accel_sgd.ipynb 35
class LRScheduler(Callback):
    order = ProgressCB.order + 2
    def __init__(self, sched): 
        super().__init__()
        self.sched = sched
    def before_fit(self): 
        self.schedo = self.sched(self.learn.opt)
    def after_batch(self): 
        if self.learn.model.training: self.schedo.step()

# %% ../nbs/06_accel_sgd.ipynb 40
class SingleBatch(Callback):
    def __init__(self): super().__init__()
    def after_batch(self): raise CancelFitException()
