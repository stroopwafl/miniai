{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de354d5c-eabd-4518-8a64-f985564dc020",
   "metadata": {},
   "source": [
    "# Conv\n",
    "\n",
    "Module for building convolutional neural networks. Includes component classes and flexible network classes for building a range of convolutional networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb744105-3123-45d4-9501-0f7d6676d678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5502942c-e8d6-4e9c-9dec-99d9b69ba5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch import nn\n",
    "from fastcore import docments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c9a344-6c13-47a9-9c2d-4e2a2c331d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d53b8c-6c9b-4121-9f66-8dd470078b0a",
   "metadata": {},
   "source": [
    "## Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac2a070-65ff-4975-81e9-cf91e2376c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ConvNormAct(nn.Module):\n",
    "    \"\"\"\n",
    "        Sequential block containing a convolutional layer, followed by a \n",
    "        normalisation layer and a ReLU activation. It is the basic component of\n",
    "        convolutional neural networks.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, # Number of channels in the input\n",
    "        out_channels, # Number of channels in the output after convolution\n",
    "        kernel_size=3, # Size of square kernel used for convolution (3 represents a square of 3x3 pixels)\n",
    "        bias=True, # If true, a bias parameter is automatically included\n",
    "        stride=2, # Size of stride\n",
    "        norm=nn.BatchNorm2d, # type of normalisation applied, default BatchNorm2d. If \"None\", no normalisation is applied.\n",
    "        act=nn.ReLU, # Activation function. If \"None\", no activation function is applied.\n",
    "        zero_norm_weights=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=kernel_size//2, bias=bias)\n",
    "        if zero_norm_weights: nn.init.constant_(conv.weight, 0.)\n",
    "        self.block = nn.Sequential(\n",
    "            conv,\n",
    "            norm(out_channels) if norm is not None else nn.Identity(),\n",
    "            act() if act is not None else nn.Identity()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x): return self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887012cc-2a86-45cd-a7c6-f12ace22c4bc",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14911d-6f3d-4cef-8bdd-5e38620f28e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ResnetStem(nn.Sequential):\n",
    "    \"\"\"\n",
    "        First block used in a resnet, containing a series of layers \n",
    "        for downsampling the input. Input is downsampled by a factor \n",
    "        of 4, leaving a pixel grid that is 4x smaller than the input.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        stem_sizes: list # stem block channel sizes — [img_channels, 32, 32, 64] common\n",
    "    ):\n",
    "        super().__init__(\n",
    "            *[\n",
    "                ConvNormAct(\n",
    "                    in_channels=stem_sizes[i],\n",
    "                    out_channels=stem_sizes[i+1],\n",
    "                    kernel_size=3,\n",
    "                    stride=2 if i==0 else 1\n",
    "                )\n",
    "            for i in range(len(stem_sizes) - 1)\n",
    "            ],\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261155c-d2e0-4632-bfa5-a811fb6b6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BottleneckBlock(nn.Module):\n",
    "    \"\"\"\n",
    "        Main component of a resnet. Contains a series of ConvNormAct \n",
    "        layers that compute over the input, in a 'wide, narrow, wide' \n",
    "        pattern with an optional stride parameter. The input is threaded\n",
    "        through the layer with a skip connection, and added to the output \n",
    "        as a residual.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, # number of channels in the input\n",
    "        out_channels, # number of channels in output after block\n",
    "        reduction=4, # factor of reduction in the bottleneck\n",
    "        stride=1 # kernel stride (only affects the first ConvNormAct layer in the block)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        reduced_features = out_channels // reduction\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            ConvNormAct(in_channels, reduced_features, kernel_size=1, stride=stride), # <----- including stride enables us to stride on this layer\n",
    "            ConvNormAct(reduced_features, reduced_features, kernel_size=3),\n",
    "            ConvNormAct(reduced_features, out_channels, kernel_size=1)\n",
    "        )\n",
    "        \n",
    "        self.shortcut = (\n",
    "            nn.Sequential(\n",
    "                ConvNormAct(in_channels, out_channels, kernel_size=1)\n",
    "            ) if in_channels != out_channels else nn.Identity()\n",
    "        )\n",
    "        \n",
    "        self.pool = (\n",
    "            nn.AvgPool2d(kernel_size=3, stride=stride, padding=1) \n",
    "            if stride != 1 else nn.Identity()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.block(x)\n",
    "        residual = self.shortcut(self.pool(residual))\n",
    "        x += residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35231b8b-4255-45ab-ab55-c505aa6aa750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ResnetStage(nn.Sequential):\n",
    "    \"\"\"\n",
    "        High level component enabling flexible construction of resnets \n",
    "        of different depths and sizes. Each stage contains a series of\n",
    "        bottleneck blocks — the number depends on the 'depth' parameter \n",
    "        passed down from the parent class.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels, # Number of channels in the input\n",
    "        out_channels, # Number of channels in the output\n",
    "        depth, # Number of BottleneckBlocks included in the stage\n",
    "        stride=2 # Stride passed down to the BottleneckBlock (only affects the first ConvNormAct layer in child BottleneckBlock)\n",
    "    ):\n",
    "        super().__init__(\n",
    "            BottleneckBlock(in_channels, out_channels, stride=stride),\n",
    "            *[\n",
    "                BottleneckBlock(out_channels, out_channels, stride=stride)\n",
    "                for i in range(depth - 1)\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e088d87c-c712-4356-bf89-8eebca1ddd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ResnetNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Main resnet class that builds the network from a series of \n",
    "        subclasses. Flexible enough to enable construction of resnets \n",
    "        across a range of widths and depths. Finishes with an average \n",
    "        pool layer followed by a fully connected layer, which produces \n",
    "        the predicted classes in the output.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_channels, # Number of channels in the image\n",
    "        stem_sizes, # Number of channels to use in ConvNormAct layers in the ResnetStem block — [32,32,64] is a common choice\n",
    "        widths, # Widths for the output of each layer. Wider layers usually means more capabilities, but more parameters and slower training\n",
    "        depths, # Number of bottleneck blocks contained in each ResnetStage\n",
    "        num_classes # Number of possible labels in the training set\n",
    "    ):\n",
    "        super().__init__()\n",
    "        stem_sizes = [img_channels, *stem_sizes]\n",
    "        self.stem = ResnetStem(stem_sizes)\n",
    "        \n",
    "        self.stages = nn.ModuleList(\n",
    "            [\n",
    "                ResnetStage(stem_sizes[-1], widths[0], depths[0], stride=1),\n",
    "                *[\n",
    "                    ResnetStage(widths[i], widths[i+1], depths[i+1])\n",
    "                    for i in range(len(widths) - 1)\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(widths[-1], num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        for stage in self.stages:\n",
    "            x = stage(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705c112-0dc1-4fde-8572-8523c2953e63",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172dec1c-76ac-47f1-8c9a-9ce922032946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74590f4f-0a66-482a-bb12-269db9648a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
